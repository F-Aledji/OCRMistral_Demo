# Mistral/Gemini OCR Demo (v2)

**Fortschrittliches System zur Verarbeitung von LieferantenbestÃ¤tigungen ("Semiramis")**

Dieses Repository enthÃ¤lt eine produktionsreife Full-Stack-LÃ¶sung zur Extraktion, Validierung und Verarbeitung von komplexen PDF-Dokumenten (speziell LieferantenbestÃ¤tigungen). Das System setzt auf einen hybriden KI-Ansatz mit **Mistral AI** (fÃ¼r die primÃ¤re Extraktion) und **Google Gemini 2.0 Flash** (als "The Judge" fÃ¼r Validierung und Selbstkorrektur).

---

## ğŸš€ Hauptfunktionen (Features)

### 1. Vereinheitlichte Verarbeitungspipeline (Unified Pipeline)
Das HerzstÃ¼ck des Systems (`core/pipeline/unified_pipeline.py`) steuert den gesamten Lebenszyklus eines Dokuments:
-   **Pre-Scan (Fast-Pass)**: Nutzt `PyMuPDF` fÃ¼r eine blitzschnelle Voranalyse (z.B. Identifikation von BA-Nummern), noch bevor teure KI-Modelle zum Einsatz kommen.
-   **Template-Injektion**: Basierend auf dem Pre-Scan werden dem KI-Modell automatisch rÃ¤umliche Koordinaten und Kontextinformationen ("Templates") mitgegeben, was die Erkennungsrate bei bekannten Layouts massiv erhÃ¶ht.
-   **Hybride Extraktion**: Flexibler Einsatz von Mistral oder Gemini zur Umwandlung unstrukturierter PDF-Daten in sauberes JSON.

### 2. "The Judge" (Intelligente Validierung & Selbstheilung)
Eine spezialisierte Korrekturebene, die die DatenintegritÃ¤t sicherstellt:
-   **Validierung**: PrÃ¼ft extrahierte Daten gegen strenge Pydantic-Schemata.
-   **Selbstkorrektur**: Scheitert die Validierung, erhÃ¤lt "The Judge" (Gemini 2.0) die Fehlermeldungen sowie den Rohkontext, um das defekte JSON automatisch zu "heilen".
-   **Confidence Scoring**: Jedes Dokument erhÃ¤lt einen Vertrauenswert (0-100%), basierend auf der VollstÃ¤ndigkeit der Felder und der Validierungstiefe.

### 3. Moderne Full-Stack Architektur
-   **Frontend**: Entwickelt mit **Next.js 16**, **TypeScript** und **Tailwind CSS**. Bietet ein modernes Dashboard zur Ãœberwachung der Warteschlange (Queue), sowie einen Split-View-Editor zur manuellen Korrektur mit PDF-Annotationen (Canvas/Konva).
-   **Backend**: Leistungsstarkes **FastAPI**-Backend mit modularer Router-Struktur.
-   **Datenbank**: **SQLite** (via SQLAlchemy) fÃ¼r einfache Deployments, strukturierte Trennung von operativen Daten und Analyse-Logs (siehe `DATABASE_PRESENTATION.md`).
-   **Containerisierung**: VollstÃ¤ndig dockerisiert (Frontend + Backend) fÃ¼r konsistente Entwicklung und Deployment.

### 4. Nachverfolgbarkeit & Audit (Traceability)
-   **Full Trace**: Jeder Schritt (Upload, OCR, Validierung, Benutzerkorrektur) wird in der `trace_entries`-Tabelle protokolliert.
-   **Dateinamen-Persistenz**: Der ursprÃ¼ngliche Dateiname bleibt Ã¼ber den gesamten Prozess erhalten â€“ von `input/` bis zur Archivierung.

---

## ğŸ— Systemarchitektur & Datenfluss

Der Datenfluss folgt einem klaren "Two Worlds"-Konzept (Trennung von Operativem Zustand und Prozess-Log):

1.  **Upload**: Dokumente landen in der `documents`-Tabelle (Status: `NEW`).
2.  **Verarbeitung**: Der **Batch-Runner** oder API-Trigger startet die Pipeline.
3.  **KI-Analyse**: Extraktion -> Validierung -> Scoring.
4.  **Datenbank**: Ergebnisse werden gespeichert.
    -   *Erfolg*: Status `VALID`.
    -   *Fehler/Unsicher*: Status `NEEDS_REVIEW` -> "The Judge" versucht Reparatur.
5.  **Human-in-the-Loop**: Mitarbeiter prÃ¼fen und korrigieren unsichere Dokumente im Frontend.

---

## ğŸ“‚ Projektstruktur

```bash
Mistral_OCR_Demo/
â”œâ”€â”€ backend/                # FastAPI Server
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/           # Konfiguration & Utils
â”‚   â”‚   â”œâ”€â”€ db.py           # Datenbank-Verbindung
â”‚   â”‚   â”œâ”€â”€ db_models.py    # SQLAlchemy ORM Modelle
â”‚   â”‚   â”œâ”€â”€ main.py         # Einstiegspunkt (Entry Point)
â”‚   â”‚   â”œâ”€â”€ routers/        # API Endpunkte (documents, annotations)
â”‚   â”‚   â”œâ”€â”€ services/       # GeschÃ¤ftslogik (PreScan, OCR, Pipeline)
â”‚   â”‚   â””â”€â”€ trace_models.py # Audit-Logging Modelle
â”‚   â”œâ”€â”€ tests/              # Pytest Test-Suite
â”‚   â””â”€â”€ data/               # Lokaler Speicher fÃ¼r PDFs
â”œâ”€â”€ frontend/               # Next.js 16 Applikation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/            # Pages & Routing
â”‚   â”‚   â”œâ”€â”€ components/     # UI Komponenten (PDFViewer, Sidebar)
â”‚   â”‚   â””â”€â”€ lib/            # Utilities (API Client)
â”‚   â””â”€â”€ public/             # Statische Assets
â”œâ”€â”€ core/                   # Geteilte Pipeline-Logik
â”‚   â”œâ”€â”€ pipeline/           # UnifiedPipeline Logik
â”‚   â””â”€â”€ prompts/            # System Prompts fÃ¼r LLMs
â”œâ”€â”€ docker-compose.yml      # Docker Orchestrierung
â””â”€â”€ requirements.txt        # Python AbhÃ¤ngigkeiten
```

---

## ğŸ›  Installation & Start

### Voraussetzungen
-   **Python 3.10+**
-   **Node.js 20+** (fÃ¼r lokale Frontend-Entwicklung)
-   **Docker** (optional, empfohlen fÃ¼r einfachen Start)
-   **API Keys**:
    -   Google Cloud Credentials (JSON) fÃ¼r Gemini
    -   Mistral API Key (falls Mistral genutzt wird)

### Konfiguration
Erstellen Sie eine `.env` Datei im Hauptverzeichnis:

```env
# AI Provider Keys
GOOGLE_APPLICATION_CREDENTIALS="pfad/zu/credentials/gcp-key.json"
GEMINI_PROJECT_ID="dein-projekt-id"
MISTRAL_API_KEY="dein-mistral-key"

# Datenbank (Optional, Standard ist lokale SQLite)
DATABASE_URL="sqlite:///./backend/demo.db"
```

---

### Option A: Start mit Docker (Empfohlen)

Der einfachste Weg, das gesamte System zu starten.

1.  **Bauen und Starten**
    ```bash
    docker-compose up --build
    ```
2.  **App Aufrufen**
    -   Frontend: [http://localhost:3000](http://localhost:3000)
    -   Backend API: [http://localhost:8000/docs](http://localhost:8000/docs)

---

### Option B: Manuelle lokale Entwicklung

#### 1. Backend Einrichten
```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r ../requirements.txt

# Server Starten
python -m uvicorn app.main:app --reload
```
*Das Backend lÃ¤uft unter `http://localhost:8000`*

#### 2. Frontend Einrichten
```bash
cd frontend
npm install

# Dev Server Starten
npm run dev
```
*Das Frontend lÃ¤uft unter `http://localhost:3000`*

---

## ğŸ–¥ Bedienung

### 1. Dokumenten-Upload
-   Navigieren Sie zum Dashboard.
-   Ziehen Sie PDF-Dateien in den Upload-Bereich.
-   Der **Pre-Scan** lÃ¤uft sofort an.

### 2. Pipeline-Verarbeitung
-   Nutzen Sie das **"Batch Run"** Skript oder triggern Sie die Verarbeitung Ã¼ber die UI.
-   Manuell Ã¼ber Terminal:
    ```bash
    python batch_runner.py --input "data/input"
    ```

### 3. Review & Korrektur
-   Ã–ffnen Sie die **"Review Queue"** im Frontend.
-   Klicken Sie auf ein Dokument fÃ¼r den **Split-View Editor**.
-   **Links**: PDF-Viewer mit Bounding-Boxes.
-   **Rechts**: Extrahiertes Daten-Formular.
-   Korrigieren Sie Fehler und klicken Sie auf **"Approve"**.

---

## ğŸ“š API Dokumentation

Das Backend bietet eine interaktive Swagger-Dokumentation.
Sobald der Server lÃ¤uft, besuchen Sie:
ğŸ‘‰ **[http://localhost:8000/docs](http://localhost:8000/docs)**

### Wichtige Endpunkte
-   `POST /api/v1/documents/upload`: Upload neuer Dokumente.
-   `GET /api/v1/documents/queue`: Abruf der Warteschlange.
-   `GET /api/v1/documents/{id}`: Detailansicht eines Dokuments.
-   `POST /api/v1/documents/{id}/claim`: Dokument fÃ¼r Bearbeitung sperren ("Claiming").

---

## ğŸ¤ Mitwirken (Contributing)

1.  Feature-Branch erstellen (`git checkout -b feature/tolle-funktion`)
2.  Ã„nderungen committen (`git commit -m 'Add tolle funktion'`)
3.  Push auf den Branch (`git push origin feature/tolle-funktion`)
4.  Pull Request Ã¶ffnen

---

## ğŸ“„ Lizenz

ProprietÃ¤r - Nur fÃ¼r internen Gebrauch.
